{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "- Comparing clean and raw dataset to understand the discrepancy in autistic sample\n",
    "---\n",
    "- The cleaned dataset is a carefully matched case-control study\n",
    "- Only 1,450 autistic participants were included in the final analysis (likely the ones with complete data and good matches)\n",
    "- The remaining autistic participants were excluded due to:\n",
    "- Incomplete data\n",
    "- Inability to find appropriate control matches\n",
    "- Quality control criteria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the large CSV file\n",
    "csv_path = '/Users/eb2007/Library/CloudStorage/OneDrive-UniversityofCambridge/Documents/PhD/data/data_c4_raw.csv'\n",
    "\n",
    "# Read a small sample to infer dtypes and preview\n",
    "sample = pd.read_csv(csv_path, nrows=5000)\n",
    "display(sample.info())\n",
    "display(sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the full dataset\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print('Shape:', df.shape)\n",
    "    print('Columns:', df.columns.tolist())\n",
    "    print('Memory usage (MB):', df.memory_usage(deep=True).sum() / 1e6)\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    print('Missing values per column:')\n",
    "    print(df.isnull().sum())\n",
    "    display(df.describe(include=\"all\"))\n",
    "except MemoryError:\n",
    "    print('MemoryError: Consider loading with chunksize or specifying dtypes.')\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Counting autism diagnoses\n",
    "\n",
    "- this is pre-cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of relevant columns\n",
    "diagnosis_cols = [f'diagnosis_{i}' for i in range(9)]\n",
    "autism_diag_cols = [f'autism_diagnosis_{i}' for i in range(3)]\n",
    "\n",
    "# Ensure columns exist in the DataFrame\n",
    "diagnosis_cols = [col for col in diagnosis_cols if col in df.columns]\n",
    "autism_diag_cols = [col for col in autism_diag_cols if col in df.columns]\n",
    "\n",
    "# Condition 1: Any '2' in diagnosis columns\n",
    "diagnosis_autistic = df[diagnosis_cols].apply(lambda row: (row == 2).any() or (row == '2').any(), axis=1)\n",
    "\n",
    "# Condition 2: Any '1', '2', or '3' in autism_diagnosis columns\n",
    "autism_diag_autistic = df[autism_diag_cols].apply(lambda row: row.isin([1, 2, 3]).any() or row.isin(['1', '2', '3']).any(), axis=1)\n",
    "\n",
    "# Combine conditions\n",
    "autistic_participants = diagnosis_autistic | autism_diag_autistic\n",
    "\n",
    "# Count\n",
    "num_autistic = autistic_participants.sum()\n",
    "print(f'Number of autistic participants: {num_autistic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Exploring clean dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned data\n",
    "clean_csv_path = '/Users/eb2007/Library/CloudStorage/OneDrive-UniversityofCambridge/Documents/PhD/data/data_c4_clean.csv'\n",
    "df_clean = pd.read_csv(clean_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reapeat autistic participants count logic \n",
    "diagnosis_cols = [f'diagnosis_{i}' for i in range(9) if f'diagnosis_{i}' in df_clean.columns]\n",
    "autism_diag_cols = [f'autism_diagnosis_{i}' for i in range(3) if f'autism_diagnosis_{i}' in df_clean.columns]\n",
    "\n",
    "diagnosis_autistic = df_clean[diagnosis_cols].apply(lambda row: (row == 2).any() or (row == '2').any(), axis=1)\n",
    "autism_diag_autistic = df_clean[autism_diag_cols].apply(lambda row: row.isin([1, 2, 3]).any() or row.isin(['1', '2', '3']).any(), axis=1)\n",
    "autistic_participants = diagnosis_autistic | autism_diag_autistic\n",
    "num_autistic = autistic_participants.sum()\n",
    "print(f'Number of autistic participants in cleaned data: {num_autistic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# comparing discrepancy between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare sizes and columns of raw and clean data\n",
    "\n",
    "print(\"Raw dataset shape:\", df.shape)\n",
    "print(\"Cleaned dataset shape:\", df_clean.shape)\n",
    "print(\"Raw columns:\", df.columns.tolist())\n",
    "print(\"Cleaned columns:\", df_clean.columns.tolist())\n",
    "\n",
    "#compare value counts \n",
    "for col in diagnosis_cols + autism_diag_cols:\n",
    "    if col in df.columns and col in df_clean.columns:\n",
    "        print(f\"{col} value counts (raw):\")\n",
    "        print(df[col].value_counts(dropna=False))\n",
    "        print(f\"{col} value counts (clean):\")\n",
    "        print(df_clean[col].value_counts(dropna=False))\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for deduplication \n",
    "# Check unique participants in both datasets\n",
    "print(\"Unique userids in raw:\", df['userid'].nunique())\n",
    "print(\"Unique userids in clean:\", df_clean['userid'].nunique())\n",
    "print(\"Total rows in raw:\", len(df))\n",
    "print(\"Total rows in clean:\", len(df_clean))\n",
    "\n",
    "#check filtering column \n",
    "print(\"autismvscontrols_1450matched value counts:\")\n",
    "print(df_clean['autismvscontrols_1450matched'].value_counts(dropna=False))\n",
    "\n",
    "# Check if participants with autism diagnoses had more missing data\n",
    "autism_participants_raw = df[df['diagnosis_0'] == 2.0]\n",
    "print(\"Missing data in autism participants (raw):\")\n",
    "print(autism_participants_raw.isnull().sum())\n",
    "\n",
    "# check the matching column (new column in clean data)\n",
    "print(\"autismvscontrols_1450matched distribution:\")\n",
    "print(df_clean['autismvscontrols_1450matched'].value_counts(dropna=False))\n",
    "print(\"\\nAutistic participants in this column:\")\n",
    "autism_in_matched = df_clean[df_clean['autismvscontrols_1450matched'] == 1]  # or whatever value indicates autism\n",
    "print(f\"Count: {len(autism_in_matched)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the #NULL! string values to get the actual matched sample\n",
    "actual_matched = df_clean[df_clean['autismvscontrols_1450matched'] != '#NULL!']\n",
    "print(f\"Actual matched sample size: {len(actual_matched)}\")\n",
    "\n",
    "# Now count autistic vs controls\n",
    "autism_matched = actual_matched[actual_matched['autismvscontrols_1450matched'].isin([1.0, 1.00])]\n",
    "controls_matched = actual_matched[actual_matched['autismvscontrols_1450matched'] == 2.00]\n",
    "\n",
    "print(f\"Autistic in matched sample: {len(autism_matched)}\")\n",
    "print(f\"Controls in matched sample: {len(controls_matched)}\")\n",
    "\n",
    "# The numbers should be:\n",
    "# 1,140 + 310 = 1,450 autistic participants\n",
    "# 1,450 control participants\n",
    "# Total: 2,900 participants\n",
    "\n",
    "print(\"Expected autistic (1.00 + 1.0):\", 1140 + 310)\n",
    "print(\"Expected controls (2.00):\", 1450)\n",
    "print(\"Expected total matched sample:\", 1450 + 1450)\n",
    "\n",
    "# For the matched sample only\n",
    "diagnosis_cols = [f'diagnosis_{i}' for i in range(9) if f'diagnosis_{i}' in actual_matched.columns]\n",
    "autism_diag_cols = [f'autism_diagnosis_{i}' for i in range(3) if f'autism_diagnosis_{i}' in actual_matched.columns]\n",
    "\n",
    "# Apply your original logic to the matched sample\n",
    "diagnosis_autistic = actual_matched[diagnosis_cols].apply(lambda row: (row == 2).any() or (row == '2').any(), axis=1)\n",
    "autism_diag_autistic = actual_matched[autism_diag_cols].apply(lambda row: row.isin([1, 2, 3]).any() or row.isin(['1', '2', '3']).any(), axis=1)\n",
    "autistic_participants_matched = diagnosis_autistic | autism_diag_autistic\n",
    "\n",
    "print(f\"Autistic participants in matched sample (by diagnosis): {autistic_participants_matched.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what values are actually in the matching column for autistic participants\n",
    "autism_by_diagnosis = actual_matched[autistic_participants_matched]\n",
    "print(\"Matching column values for participants identified as autistic by diagnosis:\")\n",
    "print(autism_by_diagnosis['autismvscontrols_1450matched'].value_counts())\n",
    "\n",
    "# Check what values are in the matching column for all matched participants\n",
    "print(\"\\nAll matching column values in matched sample:\")\n",
    "print(actual_matched['autismvscontrols_1450matched'].value_counts())\n",
    "\n",
    "# The issue might be that 1.00 and 1.0 are being treated differently\n",
    "print(\"Data types of matching column values:\")\n",
    "print(actual_matched['autismvscontrols_1450matched'].apply(type).value_counts())\n",
    "\n",
    "# Try a more robust way to identify autistic participants\n",
    "autism_1_0 = actual_matched[actual_matched['autismvscontrols_1450matched'] == 1.0]\n",
    "autism_1_00 = actual_matched[actual_matched['autismvscontrols_1450matched'] == 1.00]\n",
    "autism_1_float = actual_matched[actual_matched['autismvscontrols_1450matched'].astype(float) == 1.0]\n",
    "\n",
    "print(f\"Value 1.0 (exact): {len(autism_1_0)}\")\n",
    "print(f\"Value 1.00 (exact): {len(autism_1_00)}\")\n",
    "print(f\"Value 1.0 (as float): {len(autism_1_float)}\")\n",
    "\n",
    "# Check if participants with matching column = 1.0/1.00 have autism diagnoses\n",
    "autism_by_matching = actual_matched[actual_matched['autismvscontrols_1450matched'].isin([1.0, 1.00])]\n",
    "print(f\"Participants with matching column indicating autism: {len(autism_by_matching)}\")\n",
    "\n",
    "# Check their diagnosis data\n",
    "diagnosis_autistic_matching = autism_by_matching[diagnosis_cols].apply(lambda row: (row == 2).any() or (row == '2').any(), axis=1)\n",
    "autism_diag_autistic_matching = autism_by_matching[autism_diag_cols].apply(lambda row: row.isin([1, 2, 3]).any() or row.isin(['1', '2', '3']).any(), axis=1)\n",
    "autistic_by_both = diagnosis_autistic_matching | autism_diag_autistic_matching\n",
    "\n",
    "print(f\"Of those, how many have autism diagnoses: {autistic_by_both.sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (questionnaire_asc)",
   "language": "python",
   "name": "questionnaire_asc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
