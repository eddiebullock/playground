{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load data \n",
    "from src.data_loader import load_data\n",
    "\n",
    "# load the data \n",
    "df = load_data(\"/Users/eb2007/Library/CloudStorage/OneDrive-UniversityofCambridge/Documents/PhD/data/data_c4_raw.csv\")\n",
    "\n",
    "# basic info \n",
    "print(\"dataset shape:\", df.shape)\n",
    "print(\"\\ndata types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nmissing values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# address the target var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check autism diagnosis columns (should have values 1, 2, or 3)\n",
    "print(\"Autism diagnosis columns:\")\n",
    "for col in [col for col in df.columns if 'autism_diagnosis' in col]:\n",
    "    print(f\"{col}: {df[col].value_counts().to_dict()}\")\n",
    "    print(f\"Missing: {df[col].isnull().sum()}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Check regular diagnosis columns (should have value 2 for autism)\n",
    "print(\"\\nRegular diagnosis columns:\")\n",
    "for col in [col for col in df.columns if col.startswith('diagnosis_') and not 'autism' in col]:\n",
    "    print(f\"{col}: {df[col].value_counts().to_dict()}\")\n",
    "    print(f\"Missing: {df[col].isnull().sum()}\")\n",
    "    print(\"---\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what diagnosis columns actually exist \n",
    "print(\"all columns containing 'diagnosis':\")\n",
    "diagnosis_related = [col for col in df.columns if 'diagnosis' in col]\n",
    "print(diagnosis_related)\n",
    "\n",
    "print(\"\\nall autism diagnosis columns:\")\n",
    "autism_diag = [col for col in df.columns if 'autism_diagnosis' in col]\n",
    "print(autism_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correct columns names \n",
    "autism_cols = [col for col in df.columns if 'autism_diagnosis' in col]\n",
    "diagnosis_cols = [col for col in df.columns if col.startswith('diagnosis_') and not 'autism' in col]\n",
    "\n",
    "print(f\"autism columns found: {autism_cols}\")\n",
    "print(f\"diagnosis columns found: {diagnosis_cols}\")\n",
    "\n",
    "# method 1 autism diagnosis columns \n",
    "if autism_cols:\n",
    "    autism_from_specific = df[autism_cols].fillna(0).ge(1).any(axis=1)\n",
    "else:\n",
    "    autism_from_specific = pd.Series([False] * len(df))\n",
    "\n",
    "# method 2 regular diagnosis columns \n",
    "if diagnosis_cols:\n",
    "    autism_from_general = df[diagnosis_cols].fillna(0).eq(2).any(axis=1)\n",
    "else: \n",
    "    autism_from_general = pd.Series([False] * len(df))\n",
    "\n",
    "df['autism_target'] = (autism_from_specific | autism_from_general).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# creating target var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns dynamically from your datafram\n",
    "autism_cols = [col for col in df.columns if 'autism_diagnosis' in col]\n",
    "diagnosis_cols = [col for col in df.columns if col.startswith('diagnosis_') and not 'autism' in col]\n",
    "\n",
    "# method 1 autism fiagnosis columns\n",
    "autism_from_specific = df[autism_cols].fillna(0).ge(1).any(axis=1)\n",
    "\n",
    "# method 2 regular diagnosis columns \n",
    "autism_from_general = df[diagnosis_cols].fillna(0).eq(2).any(axis=1)\n",
    "\n",
    "# combined target \n",
    "df['autism_target'] = (autism_from_specific | autism_from_general).astype(int)\n",
    "\n",
    "# analysis of target var \n",
    "print(\"combined target variable analysis:\")\n",
    "print(\"total cases: {len(df)}\")\n",
    "print(f\"autism cases: {df['autism_target'].sum()}\")\n",
    "print(f\"non-autism cases: {len(df) - df['autism_target'].sum()}\")\n",
    "print(f\"autism percentage: {(df['autism_target'].sum() / len(df)) * 100:.2f}%\")\n",
    "\n",
    "# check for class imbalance \n",
    "print(f\"\\nclass imbalance:\")\n",
    "print(f\"autism: {df['autism_target'].sum()} ({df['autism_target'].mean()*100:.1f}%)\")\n",
    "print(f\"non-autism: {(df['autism_target'] == 0).sum()} ({(1-df['autism_target'].mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualise class imbalance\n",
    "sns.countplot(x='autism_target', data=df)\n",
    "plt.title('class balance: autism vs non-autism')\n",
    "plt.xticks([0, 1], ['non-autism', 'autism'])\n",
    "plt.show()\n",
    "\n",
    "# age distribution \n",
    "sns.histplot(data=df, x='age', hue='autism_target', bins=30, kde=True, stat='density')\n",
    "plt.title('age distribution by autism status')\n",
    "plt.show()\n",
    "\n",
    "# sex distribution \n",
    "sex_map = {\n",
    "    1.0: 'male',\n",
    "    2.0: 'female',\n",
    "    3.0: 'other',\n",
    "    4.0: 'prefer_not_to_say',\n",
    "}\n",
    "df['sex_label'] = df['sex'].map(sex_map)\n",
    "df['sex_label'].value_counts(dropna='unknown')\n",
    "\n",
    "print(df['sex_label'].value_counts(dropna=False))\n",
    "\n",
    "sns.countplot(x='sex_label', hue='autism_target', data=df)\n",
    "plt.title('sex by autism diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questionnaire scores\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#list all questionnaire columns\n",
    "questionnaire_cols = [col for col in df.columns if any(q in col for q in ['spq_', 'eq_', 'spqr_', 'aq_'])]\n",
    "\n",
    "df_melted = df.melt(id_vars='autism_target', value_vars=questionnaire_cols,\n",
    "                             var_name='questionnaire', value_name='score')\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(x='questionnaire', y='score', hue='autism_target', data=df_melted)\n",
    "plt.title('distribution of questionnaire scores by autism diagnosis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='autism')\n",
    "plt.show()\n",
    "\n",
    "#plot violins\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.violinplot(x='questionnaire', y='score', hue='autism_target', data=df_melted, split=True)\n",
    "plt.title('violin plot of questionnaire scores by autism diagnosis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='autism')\n",
    "plt.show()\n",
    "\n",
    "# facegrid \n",
    "g = sns.FacetGrid(df_melted, col='questionnaire', col_wrap=5, height=3, sharey=False)\n",
    "g.map(sns.boxplot, \"autism_target\", \"score\", order=[0, 1])\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('boxplot of questionnaire scores by autism diagnosis')\n",
    "plt.show()\n",
    "\n",
    "# heatmap of mean differences \n",
    "means = df.groupby('autism_target')[questionnaire_cols].mean().T\n",
    "means['diff'] = means[1] - means[0]\n",
    "plt.figure(figsize=(10, 1))\n",
    "sns.heatmap(means[['diff']].T, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('mean score difference (autism - non-autism)')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# handling missing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis missing data\n",
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=missing.head(20), y=missing.head(20).index)\n",
    "plt.title('top 20 feature by missing data fraction')\n",
    "plt.xlabel('fraction missing')\n",
    "plt.show()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove test user IDs \n",
    "df = df[df['userid'] > 174283]\n",
    "\n",
    "# impute demographic columns with 'unknown\n",
    "demographic_cols = ['sex', 'handedness', 'education', 'occupation', 'country_region']\n",
    "for col in demographic_cols:\n",
    "    df[col] = df[col].fillna('unknown')\n",
    "\n",
    "# impute questionnaire scores with median\n",
    "questionnaire_cols = [col for col in df.columns if any(q in col for q in ['spq_', 'eq_', 'sqr_', 'aq_'])]\n",
    "df[questionnaire_cols] = df[questionnaire_cols].fillna(df[questionnaire_cols].median())\n",
    "\n",
    "# drop rows with too much missin data in key features \n",
    "df = df.dropna(subset=questionnaire_cols)\n",
    "\n",
    "# one hot encode demographic columns\n",
    "demographic_cols = ['sex', 'handedness', 'education', 'occupation', 'country_region']\n",
    "df = pd.get_dummies(df, columns=demographic_cols, drop_first=True)\n",
    "print(df.dtypes.value_counts())\n",
    "print(df.select_dtypes(include='object').columns)\n",
    "\n",
    "# do NOT impute diagnosis or autism diagnosis columns\n",
    "diagnosis_cols = [col for col in df.columns if col.startswith('diagnosis_') and not 'autism' in col]\n",
    "autism_cols = [col for col in df.columns if 'autism_diagnosis' in col]\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(\"remaining missing values:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\ndata types after encoding :\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(df.dtypes.tail(10))\n",
    "\n",
    "print(\"\\nquestionnaire feature means (should be around 0):\")\n",
    "print(df[questionnaire_cols].mean())\n",
    "\n",
    "print(\"questionnaire features stds (should be around 1):\")\n",
    "print(df[questionnaire_cols].std())\n",
    "\n",
    "print(f\"\\npreview of processed data:\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale/normalize features \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[questionnaire_cols] = scaler.fit_transform(df[questionnaire_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop all diagnosis and autism diagnosis columns to prevent data leakage\n",
    "diagnosis_cols = [col for col in df.columns if col.startswith('diagnosis_') and not 'autism' in col]\n",
    "autism_diag_cols = [col for col in df.columns if 'autism_diagnosis' in col]\n",
    "x = df.drop(columns=['autism_target'] + diagnosis_cols + autism_diag_cols)\n",
    "y = df['autism_target']\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"train shape: {x_train.shape}, test shape: {x_test.shape}\")\n",
    "print(f\"train autism%: {y_train.mean()*100:.2f}%, test autism%: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Check for categorical columns in the data\n",
    "categorical_cols = x_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = x_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(x_test)\n",
    "y_probs = pipeline.predict_proba(x_test)[:, 1]  # Fixed typo in predict_proba\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_probs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (c4_play2)",
   "language": "python",
   "name": "c4_play2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
